{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Video dubbing from English to Assamese Language using AI","metadata":{}},{"cell_type":"markdown","source":"### Note: Run this code on Kaagle and use Accelerator \"GPU P100\" while running the code. Make sure to activate it in the 'Settings'. To use accelerator first verify Kaagle account,","metadata":{}},{"cell_type":"code","source":"!pip install python-multipart\n!pip install uvicorn\n!pip install fastapi\n!pip install nest_asyncio==1.5.8\n!pip install -U openai-whisper\n!pip install pydub\n!pip install ffmpeg\n!pip install praat-parselmouth transformers torch \n!pip install parler_tts\n!pip install demucs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T16:14:45.432677Z","iopub.execute_input":"2025-05-15T16:14:45.432859Z","iopub.status.idle":"2025-05-15T16:44:56.919061Z","shell.execute_reply.started":"2025-05-15T16:14:45.432838Z","shell.execute_reply":"2025-05-15T16:44:56.918337Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b3eb35fb910>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/python-multipart/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b3eb363ad10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/python-multipart/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b3eb3638150>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/python-multipart/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b3eb35a8390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/python-multipart/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b3eb35fe4d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/python-multipart/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement python-multipart (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for python-multipart\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a6794fb49d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/uvicorn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a6794e8a290>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/uvicorn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a6794da8cd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/uvicorn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a6794dabbd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/uvicorn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a6794fd1350>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/uvicorn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement uvicorn (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for uvicorn\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e5b3bbf2350>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e5b3b25ab50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e5b3b35f490>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e5b3b269910>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e5b3b2681d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement fastapi (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for fastapi\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f396b0e28d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nest-asyncio/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f396b1e3950>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nest-asyncio/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f396b0e4250>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nest-asyncio/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f396b0fe850>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nest-asyncio/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f396b0c90d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nest-asyncio/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement nest_asyncio==1.5.8 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for nest_asyncio==1.5.8\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79886c9ca910>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/openai-whisper/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79886c390590>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/openai-whisper/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79886c3fe3d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/openai-whisper/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79886c3098d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/openai-whisper/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x79886c303190>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/openai-whisper/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement openai-whisper (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for openai-whisper\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e4af25d69d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ffmpeg/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e4af26ca6d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ffmpeg/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e4af25d8f90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ffmpeg/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e4af25b7d90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ffmpeg/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e4af2550110>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ffmpeg/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement ffmpeg (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for ffmpeg\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c32668d78d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/praat-parselmouth/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c32668a6290>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/praat-parselmouth/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c32667b2690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/praat-parselmouth/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c32667eb090>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/praat-parselmouth/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c32667d4ad0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/praat-parselmouth/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement praat-parselmouth (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for praat-parselmouth\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ec1c3979e50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parler-tts/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ec1c3a72490>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parler-tts/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ec1c394e510>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parler-tts/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ec1c39769d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parler-tts/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7ec1c3947c90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/parler-tts/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement parler_tts (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for parler_tts\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f248ee2b550>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/demucs/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f248ee60890>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/demucs/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f248ef40050>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/demucs/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f248ee3a310>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/demucs/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f248ee39f90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/demucs/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement demucs (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for demucs\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install pyngrok\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyngrok import ngrok \nngrok.set_auth_token(\"Auth_token from ngrok website\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T15:52:35.330Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Without Demucs","metadata":{}},{"cell_type":"code","source":"import os\nimport asyncio\nimport gc\nimport re\nimport torch\nimport whisper\nimport librosa\nimport soundfile as sf\nimport numpy as np\nfrom pyngrok import ngrok\nfrom pydub import AudioSegment\nfrom fastapi import FastAPI, File, UploadFile, HTTPException, Form, BackgroundTasks\nfrom fastapi.responses import FileResponse, JSONResponse\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom moviepy.editor import VideoFileClip, AudioFileClip\nfrom transformers import pipeline, AutoTokenizer\nfrom parler_tts import ParlerTTSForConditionalGeneration\nimport nest_asyncio\n\n# Apply nest_asyncio to allow nested event loops\nnest_asyncio.apply()\n\n# Initialize FastAPI app\napp = FastAPI(title=\"Video Translation API\", \n              description=\"Translates videos from English to Assamese with TTS\")\n\n# CORS middleware to allow frontend interactions\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Global paths for working directory\nWORKING_DIR = \"/kaggle/working\"\nos.makedirs(WORKING_DIR, exist_ok=True)\n\n# Determine device\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# Global model variables - initialized on demand\ntranslation_pipeline = None\ntts_model = None\ntts_tokenizer = None\ndesc_tokenizer = None\nwhisper_model = None\n\n# Function to split text into sentences for better translation\ndef split_into_sentences(text):\n    \"\"\"Split text into sentences more reliably.\"\"\"\n    # Handle common abbreviations to avoid incorrect splitting\n    text = re.sub(r'(?<=[A-Za-z])\\.(?=[A-Za-z])', '. ', text)\n    \n    # Split on period, exclamation mark, or question mark followed by space or quote\n    sentences = re.split(r'(?<=[.!?])\\s+|(?<=[.!?])\"', text)\n    \n    # Clean up the sentences\n    sentences = [s.strip() for s in sentences if s.strip()]\n    \n    # Additional checks to merge incorrectly split sentences\n    merged_sentences = []\n    current = \"\"\n    \n    for s in sentences:\n        if current and (not current[-1] in \".!?\" or len(s) == 1 or s[0].islower()):\n            current += \" \" + s\n        else:\n            if current:\n                merged_sentences.append(current)\n            current = s\n    \n    if current:\n        merged_sentences.append(current)\n    \n    # Final check to ensure each sentence ends with punctuation\n    final_sentences = []\n    for s in merged_sentences:\n        if not s[-1] in \".!?\":\n            s += \".\"\n        final_sentences.append(s)\n    \n    return final_sentences\n\n# Lazy loading functions for models\ndef load_whisper_model():\n    global whisper_model\n    if whisper_model is None:\n        print(\"Loading Whisper model...\")\n        whisper_model = whisper.load_model(\"medium\").to(device)\n    return whisper_model\n\ndef load_translation_model():\n    global translation_pipeline\n    if translation_pipeline is None:\n        print(\"Loading translation model...\")\n        translation_pipeline = pipeline(\n            \"translation\", \n            model=\"facebook/nllb-200-distilled-600M\", \n            device=0 if \"cuda\" in device else -1\n        )\n    return translation_pipeline\n\ndef load_tts_models():\n    global tts_model, tts_tokenizer, desc_tokenizer\n    if tts_model is None:\n        print(\"Loading TTS model...\")\n        tts_model_name = \"ai4bharat/indic-parler-tts-pretrained\"\n        tts_model = ParlerTTSForConditionalGeneration.from_pretrained(tts_model_name).to(device)\n        tts_tokenizer = AutoTokenizer.from_pretrained(tts_model_name)\n        \n        # Use the correct attribute name for the text encoder\n        try:\n            desc_tokenizer = AutoTokenizer.from_pretrained(tts_model.config.text_encoder_id)\n        except (AttributeError, ValueError):\n            try:\n                desc_tokenizer = AutoTokenizer.from_pretrained(tts_model.config.text_encoder._name_or_path)\n            except (AttributeError, ValueError):\n                print(\"Falling back to default encoder path\")\n                desc_tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n    \n    return tts_model, tts_tokenizer, desc_tokenizer\n\ndef translate_text(text, src_lang=\"eng_Latn\", tgt_lang=\"asm_Beng\"):\n    \"\"\"Translate text from source language to target language\"\"\"\n    translator = load_translation_model()\n    \n    # Split into sentences for better translation quality\n    sentences = split_into_sentences(text)\n    \n    translated_sentences = []\n    for sentence in sentences:\n        if sentence:  # Skip empty sentences\n            translation = translator(sentence, src_lang=src_lang, tgt_lang=tgt_lang, max_length=400)\n            translated_text = translation[0]['translation_text']\n            translated_sentences.append(translated_text)\n            print(f\"Translated: {sentence[:50]}... → {translated_text[:50]}...\")\n    \n    return translated_sentences\n\ndef generate_tts_audio(sentences):\n    \"\"\"Generate TTS audio for each sentence and combine them\"\"\"\n    tts_model, tts_tokenizer, desc_tokenizer = load_tts_models()\n    \n    # TTS voice description\n    description = (\n        \"Amit. \"\n        \"Clear native speaker with moderate speed and pitch. Very high quality \"\n        \"voice sounding natural and close up.\"\n    )\n    \n    audio_segments = []\n    \n    for idx, sentence in enumerate(sentences):\n        try:\n            print(f\"Generating audio for sentence {idx+1}/{len(sentences)}: {sentence[:30]}...\")\n            \n            # Tokenize the sentence and description\n            prompt_input = tts_tokenizer(sentence, return_tensors=\"pt\").to(device)\n            desc_input = desc_tokenizer(description, return_tensors=\"pt\").to(device)\n\n            with torch.no_grad():\n                gen_audio = tts_model.generate(\n                    input_ids=desc_input.input_ids,\n                    attention_mask=desc_input.attention_mask,\n                    prompt_input_ids=prompt_input.input_ids,\n                    prompt_attention_mask=prompt_input.attention_mask\n                )\n\n            # Process the audio\n            audio_array = gen_audio.cpu().numpy().squeeze()\n            \n            # Clear GPU memory after processing\n            del gen_audio\n            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n            \n            # Determine if we have multiple audio items\n            if audio_array.ndim == 1:\n                audio_items = [audio_array]\n            else:\n                # For multi-dimensional arrays, treat each row as a separate audio item\n                audio_items = [audio_array[i] for i in range(audio_array.shape[0])]\n            \n            # We'll use the first audio variant for each sentence\n            if len(audio_items) > 0:\n                output_path = os.path.join(WORKING_DIR, f\"audio_chunk_{idx}.wav\")\n                sf.write(output_path, audio_items[0], tts_model.config.sampling_rate)\n                \n                # Add to our audio segments collection\n                audio_segment = AudioSegment.from_file(output_path)\n                audio_segments.append(audio_segment)\n                \n                # Clear numpy arrays to free memory\n                del audio_items, audio_array\n            \n        except Exception as e:\n            print(f\"Error generating audio for sentence {idx}: {e}\")\n            # Continue with next sentence\n    \n    # Combine audio segments with small pauses\n    if audio_segments:\n        combined_audio = audio_segments[0]\n        for segment in audio_segments[1:]:\n            combined_audio += AudioSegment.silent(duration=300) + segment\n        \n        output_path = os.path.join(WORKING_DIR, \"translated_audio.wav\")\n        combined_audio.export(output_path, format=\"wav\")\n        return output_path\n    \n    return None\n\ndef adjust_audio_to_video_duration(audio_path, video_duration_ms):\n    \"\"\"Adjust audio to match video duration\"\"\"\n    audio = AudioSegment.from_file(audio_path)\n    audio_duration_ms = len(audio)\n    \n    # Calculate difference\n    diff_ms = video_duration_ms - audio_duration_ms\n    \n    print(f\"Audio duration: {audio_duration_ms}ms, Video duration: {video_duration_ms}ms, Difference: {diff_ms}ms\")\n    \n    # If difference is minimal (less than 100ms), no adjustment needed\n    if abs(diff_ms) < 100:\n        print(\"Audio and video durations match closely. No adjustment needed.\")\n        return audio_path\n    \n    # Adjust audio\n    if diff_ms < 0:\n        # Audio is longer than video, speed up slightly\n        print(f\"Audio is {-diff_ms}ms longer than video. Adjusting tempo...\")\n        speedup_factor = video_duration_ms / audio_duration_ms\n        \n        if 0.9 <= speedup_factor <= 1.1:\n            adjusted_audio = audio._spawn(audio.raw_data, overrides={\n                \"frame_rate\": int(audio.frame_rate * speedup_factor)\n            })\n            adjusted_audio = adjusted_audio.set_frame_rate(audio.frame_rate)\n        else:\n            print(f\"Required speedup factor {speedup_factor:.3f} is too extreme. Trimming audio instead.\")\n            adjusted_audio = audio[:video_duration_ms]\n    else:\n        # Audio is shorter than video, add silence\n        print(f\"Audio is {diff_ms}ms shorter than video. Adding silence...\")\n        silence_begin = AudioSegment.silent(duration=diff_ms//4)\n        silence_end = AudioSegment.silent(duration=diff_ms - diff_ms//4)\n        adjusted_audio = silence_begin + audio + silence_end\n    \n    # Save adjusted audio\n    adjusted_path = os.path.join(WORKING_DIR, \"adjusted_audio.wav\")\n    adjusted_audio.export(adjusted_path, format=\"wav\")\n    return adjusted_path\n\ndef free_memory():\n    \"\"\"Free up GPU memory\"\"\"\n    global translation_pipeline, tts_model, tts_tokenizer, desc_tokenizer, whisper_model\n    \n    if translation_pipeline is not None:\n        del translation_pipeline\n        translation_pipeline = None\n    \n    if tts_model is not None:\n        del tts_model\n        del tts_tokenizer\n        del desc_tokenizer\n        tts_model = None\n        tts_tokenizer = None\n        desc_tokenizer = None\n    \n    if whisper_model is not None:\n        del whisper_model\n        whisper_model = None\n    \n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    print(\"Memory freed.\")\n\n# Define background task for processing\nasync def process_video_translation(input_video_path, target_language=\"asm_Beng\"):\n    try:\n        print(f\"Processing video: {input_video_path}\")\n        \n        # Extract audio from video\n        video = VideoFileClip(input_video_path)\n        video_duration_ms = int(video.duration * 1000)\n        \n        # Extract audio\n        audio_path = os.path.join(WORKING_DIR, \"extracted_audio.wav\")\n        video.audio.write_audiofile(audio_path)\n        \n        # Transcribe audio\n        whisper_model = load_whisper_model()\n        audio_data, sr = librosa.load(audio_path, sr=16000)\n        result = whisper_model.transcribe(audio_data)\n        recognized_text = result[\"text\"]\n        \n        print(f\"Transcribed text: {recognized_text[:100]}...\")\n        \n        # Translate text\n        translated_sentences = translate_text(recognized_text, tgt_lang=target_language)\n        \n        # Generate TTS audio\n        translated_audio_path = generate_tts_audio(translated_sentences)\n        \n        if not translated_audio_path:\n            raise Exception(\"Failed to generate translated audio\")\n        \n        # Adjust audio to match video duration\n        adjusted_audio_path = adjust_audio_to_video_duration(translated_audio_path, video_duration_ms)\n        \n        # Merge audio with video\n        output_path = os.path.join(WORKING_DIR, \"translated_video.mp4\")\n        translated_audio = AudioFileClip(adjusted_audio_path)\n        final_clip = video.set_audio(translated_audio)\n        final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n        \n        # Close video files\n        video.close()\n        translated_audio.close()\n        \n        # Free memory\n        free_memory()\n        \n        return output_path\n    \n    except Exception as e:\n        print(f\"Error in video translation process: {e}\")\n        import traceback\n        traceback.print_exc()\n        raise e\n\n# API Endpoints\n@app.post(\"/translate-video/\")\nasync def translate_video(\n    background_tasks: BackgroundTasks,\n    file: UploadFile = File(...),\n    target_language: str = Form(\"asm_Beng\")\n):\n    \"\"\"Endpoint for video translation with file upload\"\"\"\n    try:\n        # Save uploaded video\n        input_video_path = os.path.join(WORKING_DIR, \"input_video.mp4\")\n        with open(input_video_path, \"wb\") as buffer:\n            buffer.write(await file.read())\n        \n        # Process in background\n        output_path = await process_video_translation(input_video_path, target_language)\n        \n        # Return response\n        return FileResponse(\n            path=output_path, \n            filename=\"translated_video.mp4\",\n            media_type=\"video/mp4\"\n        )\n    \n    except Exception as e:\n        return JSONResponse(\n            status_code=500,\n            content={\"error\": str(e)}\n        )\n\n@app.post(\"/translate-from-path/\")\nasync def translate_from_path(\n    video_path: str = Form(...),\n    target_language: str = Form(\"asm_Beng\")\n):\n    \"\"\"Endpoint for video translation using an existing path\"\"\"\n    try:\n        if not os.path.exists(video_path):\n            raise HTTPException(status_code=404, detail=f\"Video file not found at {video_path}\")\n        \n        # Process video\n        output_path = await process_video_translation(video_path, target_language)\n        \n        # Return response\n        return FileResponse(\n            path=output_path, \n            filename=\"translated_video.mp4\",\n            media_type=\"video/mp4\"\n        )\n    \n    except Exception as e:\n        return JSONResponse(\n            status_code=500,\n            content={\"error\": str(e)}\n        )\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint with API information\"\"\"\n    return {\n        \"message\": \"Video Translation API is running\",\n        \"endpoints\": {\n            \"/translate-video/\": \"Upload a video for translation\",\n            \"/translate-from-path/\": \"Translate a video from an existing path\",\n        }\n    }\n\n# Ngrok setup\nasync def setup_ngrok(port):\n    \"\"\"Configure and start ngrok tunnel\"\"\"\n    try:\n        # Set up your ngrok auth token if you have one\n        # ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\") # Uncomment and add your token if available\n        \n        # Start ngrok tunnel to the specified port\n        public_url = ngrok.connect(port)\n        print(f\"✅ Ngrok tunnel established: {public_url}\")\n        return public_url\n    except Exception as e:\n        print(f\"❌ Failed to establish ngrok tunnel: {e}\")\n        return None\n\nif __name__ == \"__main__\":\n    import uvicorn\n    \n    # Define port\n    PORT = 8000\n    \n    # Start ngrok in the background\n    asyncio.run(setup_ngrok(PORT))\n    \n    # Run the FastAPI app\n    uvicorn.run(app, host=\"0.0.0.0\", port=PORT)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T15:52:35.331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# With Demucs","metadata":{}},{"cell_type":"code","source":"import os\nimport asyncio\nimport subprocess\nfrom fastapi.responses import FileResponse\nimport torch\nimport whisper\nimport librosa\nimport soundfile as sf\nfrom pyngrok import ngrok\nfrom fastapi import FastAPI, File, UploadFile\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\nfrom transformers import pipeline\nfrom parler_tts import ParlerTTSForConditionalGeneration\nfrom transformers import AutoTokenizer\n\napp = FastAPI()\n\n# CORS middleware to allow frontend interactions\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Determine device\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Global models to be loaded once\ntranslation_pipe = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\", device=device)\ntts_model = ParlerTTSForConditionalGeneration.from_pretrained(\"ai4bharat/indic-parler-tts-pretrained\")\ntts_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts-pretrained\")\nwhisper_model = whisper.load_model(\"medium\")\n\ndef translate_english_to_assamese(text):\n    \"\"\"Translate text from English to Assamese\"\"\"\n    results = translation_pipe(text, src_lang=\"eng_Latn\", tgt_lang=\"asm_Beng\")\n    return results[0]['translation_text']\n\ndef generate_tts_audio(text):\n    \"\"\"Generate TTS audio for Assamese text\"\"\"\n    tts_model.to(device)\n    \n    description = (\n        \"A male speaker with an assamese accent delivers a slightly expressive \"\n        \"and animated speech with a moderate speed and pitch.\"\n    )\n    \n    description_tokenizer = AutoTokenizer.from_pretrained(tts_model.config.text_encoder._name_or_path)\n    description_input_ids = description_tokenizer(description, return_tensors=\"pt\").to(device)\n    \n    prompt_input_ids = tts_tokenizer(text, return_tensors=\"pt\").to(device)\n    \n    generation = tts_model.generate(\n        input_ids=description_input_ids.input_ids,\n        attention_mask=description_input_ids.attention_mask,\n        prompt_input_ids=prompt_input_ids.input_ids,\n        prompt_attention_mask=prompt_input_ids.attention_mask\n    )\n    \n    audio_arr = generation.cpu().numpy().squeeze()\n    return audio_arr, tts_model.config.sampling_rate\n\ndef separate_audio_sources(audio_path):\n    \"\"\"Separate vocals from background using Demucs\"\"\"\n    # Create the output directory if it doesn't exist\n    os.makedirs(\"/kaggle/working/separated\", exist_ok=True)\n    \n    # Run demucs to separate vocals and background\n    subprocess.run([\n        \"demucs\", \n        \"--two-stems=vocals\",\n        audio_path\n    ], check=True)\n    \n    # Get paths for separated audio files\n    base_filename = os.path.basename(audio_path).split('.')[0]\n    vocals_path = f\"/kaggle/working/separated/htdemucs/{base_filename}/vocals.wav\"\n    no_vocals_path = f\"/kaggle/working/separated/htdemucs/{base_filename}/no_vocals.wav\"\n    \n    return vocals_path, no_vocals_path\n\n@app.post(\"/translate-video/\")\nasync def translate_video(file: UploadFile = File(...)):\n    \"\"\"Main endpoint for video translation\"\"\"\n    try:\n        # Save uploaded video\n        input_video_path = \"/kaggle/working/input_video.mp4\"\n        with open(input_video_path, \"wb\") as buffer:\n            buffer.write(await file.read())\n        \n        # Extract audio\n        video = VideoFileClip(input_video_path)\n        audio_path = \"/kaggle/working/audio.wav\"\n        video.audio.write_audiofile(audio_path)\n        \n        # Separate vocals from background music\n        vocals_path, no_vocals_path = separate_audio_sources(audio_path)\n        \n        # Transcribe vocals only\n        audio_data, sr = librosa.load(vocals_path, sr=16000)\n        result = whisper_model.transcribe(audio_data)\n        recognized_text = result[\"text\"]\n        \n        # Translate text\n        translated_text = translate_english_to_assamese(recognized_text)\n        \n        # Generate TTS audio\n        audio_arr, sample_rate = generate_tts_audio(translated_text)\n        tts_audio_path = \"/kaggle/working/translated_audio.wav\"\n        sf.write(tts_audio_path, audio_arr, sample_rate)\n        \n        # Load the background audio and translated vocals\n        background_audio = AudioFileClip(no_vocals_path)\n        translated_vocals = AudioFileClip(tts_audio_path)\n        \n        # Adjust durations if needed\n        if background_audio.duration > translated_vocals.duration:\n            background_audio = background_audio.subclip(0, translated_vocals.duration)\n        else:\n            translated_vocals = translated_vocals.subclip(0, background_audio.duration)\n        \n        # Mix the background and translated vocals\n        final_audio = CompositeAudioClip([background_audio, translated_vocals])\n        \n        # Merge audio with video\n        final_clip = video.set_audio(final_audio)\n        output_path = \"/kaggle/working/translated_video.mp4\"\n        final_clip.write_videofile(output_path)\n        \n        return {\"message\": \"Video translation completed\", \"output_path\": output_path}\n    \n    except Exception as e:\n        return {\"error\": str(e)}\n\n@app.get(\"/download-video/\")\nasync def download_video():\n    \"\"\"Endpoint to download the translated video\"\"\"\n    output_path = \"/kaggle/working/translated_video.mp4\"\n    if os.path.exists(output_path):\n        return FileResponse(output_path, filename=\"translated_video.mp4\")\n    return {\"error\": \"Translated video not found\"}\n\nasync def start_ngrok():\n    \"\"\"Start ngrok tunnel\"\"\"\n    listener = ngrok.connect(8009)\n    print(f\"Ingress established at: {listener.url()}\")\n\ndef main():\n    import uvicorn\n    import nest_asyncio\n    \n    # Apply nest_asyncio to allow nested event loops\n    nest_asyncio.apply()\n    \n    # Start ngrok\n    ngrok.connect(8009)\n    print(f\"Ingress established at {ngrok.get_tunnels()[0].public_url}\")\n    \n    # Run FastAPI\n    uvicorn.run(app, host=\"0.0.0.0\", port=8009)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}